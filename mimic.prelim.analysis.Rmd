---
title: "Relative Sparsity Real Data Preliminary Analysis"
author: "Anonymized"
date: '2022-09-07'
output: 
  pdf_document:
    toc: true
    toc_depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Authors, date
Anonymized

Date:

```{r,echo=FALSE }
Sys.Date()
```



# Project summary 

![Summary of the methodology that we will be illustrating in this real data analysis.](imagesForPrelimAnalysis/rscondec1.png)

This is a real data analysis to illustrate our relative sparsity objective function, which allows us to derive a new policy that, like policies derived from existing methods, improves outcomes, but unlike policies derived from existing methods, is easy to explain/justify in the context of the current standard of care.  

# File summary

Filename: "mimic.prelim.analysis.Rmd" within the working directory


The file mimic.prelim.analysis.Rmd will start with the decision problem (since the covariates we choose are based on this decision problem), first doing a sort of unit test to make sure that all the data processing scripts were correct by looking at a patient in the raw data and then in the final episodes.  Then, having confirmed that the decision problem is correct, we will look at state covariates and population level summaries.

```{r,echo=FALSE }
library(latex2exp)
library(kableExtra)
library(xtable)
library(neighbr)
library(predtools)
#library(reticulate) # didn't work. for reading python numpy arrays into r
source('utils.R')
source('mc.utils.R')
source('is.R')

id.check = 52
debug = 0
tag = ""
stagesdirec = paste0("/stages",tag)
str.tag = "mimic"
gamma.select.ix = 1
manu.lam.select = 3
#other.args=list(var=0,plot.adap.lasso.ci=0,logx=0,delta.sel=1,DeltaOnlyTitle=1,gammaixleg=1,deltaixleg=1,area.plots=1.3,
#                plot.emp.var=0)

other.args=list(get.theor.var.of.ests=0,plot.adap.lasso.ci=0,logx=0,delta.sel=1,DeltaOnlyTitle=1,
                gammaixleg=1,deltaixleg=1,area.plots=1.3,
                plot.emp.var=1,use.l=0,use.gen.data=1,sample.split=0,three.arg=0,max.n.div=2,use.diff=.5)
use.diff = other.args$use.diff #1e-1

max.lambda = .5#.02
nlam = 10 #10#10
lambdas= seq(.3,1.4,length.out=nlam)#exp(seq(log(0.01),log(10),length.out=nlam))#seq(0.00001,0.6,length.out=nlam)#exp(seq(log(2e-3),log(max.lambda),length.out=nlam))#seq(0,max.lamda,length.out=nlam)
#lambdas = exp(seq(-50,log(max.lambda),length.out=nlam))
deltas = c(0)#seq(1,2,length.out=3)#seq(.5,1.5,length.out=3)[3]
gammas = c(0)#exp(c(-30,seq(-22,19,length.out=3),3))#exp(seq(-2,-1,length.out=3))#exp(seq(-2,0,length.out=3))#exp(seq(-2,0,length.out=3))[1]#exp(seq(-2,1,length.out=3))#exp(seq(-10,0,length.out=3))#exp(seq(-26,2,length.out=3))

if (debug){
  other.args=list(get.theor.var.of.ests=0,plot.adap.lasso.ci=0,logx=1,delta.sel=1,DeltaOnlyTitle=1,
                  gammaixleg=1,deltaixleg=1,area.plots=1.3,
                  plot.emp.var=1,use.l=0,use.gen.data=1,sample.split=0,three.arg=0)
  nlam = 2#5#3 #10#10
  lambdas= exp(seq(log(1e-5),log(2000),length.out=nlam))
  #lambdas = exp(seq(-50,log(max.lambda),length.out=nlam))
  deltas = c(0)#seq(.5,1.5,length.out=3)
  gammas =  c(0)#exp(c(seq(-22,19,length.out=3)))#exp(seq(-26,2,length.out=3))
  
}

#gammas = c(1e-50)
nlam = length(lambdas)
ngam = length(gammas)
ndel = length(deltas)

ncov = 10 # 8 is max
# what we want to focus on
start.t=3 # beginning of traj
# for a two stage, end.stage=3. For one stage end.stage=2
end.stage=3 # end of traj. we end early. so this is like first 30 min after hyp

other.arg.str= paste0(paste0(names(other.args),"=",other.args),collapse = "")
exp.tag = paste0("tag=",str.tag,"usediff=",use.diff,",start.t",start.t,"endStage",end.stage,"gammaselix=",
                 gamma.select.ix,"manu.sel=",manu.lam.select,"nlam=",
                 nlam,"minlam=",min(lambdas),"maxlam=",max(lambdas),"gammas=",
                 paste(formatC(gammas,digits=2,format="e"), collapse = '.'),
                 "ncov=",ncov,"use.dff=",use.diff)

```

# Supporting files
The dataset we analyze here was created by data_clean.py and np_load.py, which are in this same directory

The file data_clean.py is a heavily altered version of the code from Joe Futoma's [Github](https://github.com/dtak/POPCORN-POMDP) and the file np_load.py I wrote from scratch (it processes the output of data_clean.py).  The file data_clean.py gets covariates, fills in missing covariates, handles outliers, standardizes vasopressors, and creates trajectories. Note that data_clean.py reads its input datasets from a folder called query-data, which is generated by bash scripts in Joe's extract-scripts directory.  These bash scripts process  the raw MIMIC data ([MIMIC website](https://physionet.org/content/mimiciii-demo/1.4/) ), and I did not alter them.  

I keep data_clean.py and np_load.py in my base code directory (the directory in which mimic.prelim.analysis.Rmd is found), with the rest of my modeling code, so that when I commit git versions to this directory, these files are also committed.  

# Unit test: Patient 201098

Because the data_clean.py and np_load.py files are quite long and based on pre-existing code, we must prove that all the code and changes we made to these files are correct are correct (also, data_clean.py originally did not run at all without quite a few changes; ultimately, using this file helped me do something better than what I could have done myself, but I am not sure if in the future I might just write from scratch using Joe's code as a reference, rather than running it directly).  To prove this in this document, our strategy will be to show some raw data for a patient from query-data, which is just the output of Joe's bash scripts after processing the raw MIMIC data (I assume Joe's bash scripts, which I didn't change, are correct - they mostly just look things up and reformat), and then to show the same patient here, in the data structure that will be used for modeling.  I will just show MAP and vaso, assuming that if MAP is correct so are the other covariates, since covariates are processed similarly, and the major work goes into vaso.  This patient is ID 201098.

## Raw data

Some of this patient's raw data is here.  

```{r,echo=FALSE }
example='/Users/anonymous/Box/MIMIC/mimic-iii-v1-4/hypotension-RL/model-data2/exampleRawData201098.csv'
kable(read.csv(example)[7:14,])
```


We see that the patient had a pretty low mean arterial pressure (MAP) of 58 at 8:30 am.  They entered the cohort because MAP=58<60 (we condition on hypotension, so our model will only be valid if someone is hypotensive). ^[We begin the trajectory 0.4 minutes after this low MAP (there are a lot of measurements before 8:30, and Joe's code adds all of those earlier ones before the trajectory, so I added a buffer of 0.4 to "catch" those, and thus  we start "approximately" at the onset of hypotension).]

I will now describe what happens, but feel free also to refer to the diagram below, which might be quicker to read.

Over the next 15 minutes, from 8:30 to 8:45, the patient's MAP dropped to 48, and vasos were initiated.  Then over the next 15 minutes (8:30-8:45), with vasos being administered, their blood pressure increased to 53.  Hence, our single stage decision will use the covariates at the end of the first 15 minutes state as the $S_0$, so $S_0=48$.  The action taken will be $A_0=1,$ since vasos were given during the second 15 minutes from 8:30 to 8:45, and the final state will be the MAP we see at 8:45, which will be $S_1=53.$  Since we define $R(S_0,A_0,S_1)=S_1,$ we will have a reward therefore of 53.  So, in this case, it looks like the vasos helped increase this patient's mean arterial pressure, although the effect is not too big. 


![Arbitrary and real trajectory (patient 201098).](imagesForPrelimAnalysis/traj.png) 

Note that the states are point measurements at the end of each 15 minute period, but the actions correspond whether vasos were given or not over a 15 minute period. Note again that actions are dichotomized; Joe originally gets continuous actions, then he categorizes, then I further dichotomize.^[We are also discretizing time.  It could be a interesting future direction to have continuous actions and continuous time.]


We do vasos during a 15 minute period just because they are given as a continuous infusion, they act very quickly, and they wear off quickly. ^[So, it is better to sort of look over a time span than to try to exactly capture the peak effect - it is possible there is a subproblem with states that are very short in duration that has even more signal than what we look at.] Finally, this is not shown in the figure, but the reward is the MAP at the next time step.

Now, between the raw data I showed above and the data we use to perform the real data analysis for the paper, there is data_clean.py, np_load.py, and some parts of the mimic.R file, which has been converted into this preliminary analysis file.  I want to just show that the real data above is processed into an "episode" here in this script - a tuple $(S_0,A_0,S_1)$ that aligns with the real data we saw above for patient 201098.


```{r, echo=FALSE }
careunit = 'MICU'
if(getwd()=="/Volumes/projects/Latentdir/relative_sparsity/code_betareg/mdp_Vonly"){
  pth='/Users/anonymous/Box/MIMIC/mimic-iii-v1-4/hypotension-RL/model-data2'  
}else{
  print("stop")
  browser()
  pth='/scratch/sweisent/mimic'
  
  sink(file = paste0(exp.tag,".mimic.txt"), append = FALSE, 
       type = c("output", "message"),split = FALSE)
}



filenames <- list.files(paste0(pth,stagesdirec), pattern="*.csv", full.names=TRUE)
ldf <- lapply(filenames, read.csv)


ldf = lapply(ldf,as.matrix)
# what is available (change in np_load.py)
nStages=length(ldf)

state.dim = dim(ldf[[1]])[2] #K
nObs = dim(ldf[[1]])[1] #N

msr =  read.csv(paste0(pth,'/',tag,'multistage_rewards.csv'),header=TRUE, row.names = 1)

msa =  read.csv(paste0(pth,'/',tag,'multistage_actions.csv'),header=TRUE, row.names = 1)

# These are times corresponding to the actions and rewards, not the states. ie
# if these times are t0,t1,t2,... the state times are s_0=t-1,s_1=t0,s_2=t1,s_3=t2.
# whereas the action times are a_0=t_0, a_1=t_1, etc...
mst =  read.csv(paste0(pth,'/',tag,'multistage_times.csv'),header=TRUE, row.names = 1)
#msva = read.csv(paste0(pth,'/icu_startmultistage_vasoamts.csv'),header=TRUE, row.names = 1)
```

## Expected trajectory after all the processing

Here is what we we will want to see.  This corresponds to the raw data above. Note that I have set things up so that the decision problem we want starts at index 3 and gives us the decision for time 15 to 30.  Recall that we define reward $R(S_0,A_0,S_1)=S_1,$ so it's the blood pressure at the next step.
````{verbatim}

Index    1        2        3         4
T(min)   .4       15.4     30.4      45.4      (it's time of action, reward)
Act      1        1        a_0=1     1
S        58       58       s_0=48    53     (states are one step behind)
map      58       48       s_1=53    67
R        58       48       53        67      (One ahead of S. Time corresponds to Time above)
````

## Trajectory we see after all the processing
I will now build the table above directly from the data we have available here, which passed through data_clean.py, np_load.py, and the first part of this file.

```{r }
nte=4
nts =1
mr=msr[id.check,nts:nte]
ma=msa[id.check,nts:nte]
#msva[id.check,]
mt=mst[id.check,nts:nte] # note that these times correspond to the rewards and actions, not states
ms = rep(NA,length(nts:nte))
for (i in nts:nte){
ms[i]=(ldf[[i]][id.check,]['map']) 
}

traj.table=rbind("time(min)"=paste0(round(mt*60,2)),
                 states=paste0(ms),
                 actions=paste0(ma),
                 rewards=paste0(mr))
#colnames(traj.table)

kable(traj.table)
```
It looks like this matches expectations.


# Population level statistics

Now that we have strengthened our confidence in the pre-processing, let's look at some population level statistics.
## Percentage vaso per time 
Let's look at percentage vaso per stage. We are interested in the action that ends at 30, which will be the third column.
```{r, echo=FALSE }
pctv=apply(msa,2,mean,na.rm=TRUE)
rbind(times=round(mst[1,]*60,2),percentVaso=pctv)
```
## Vaso trajectories from time 0-15 and 15-30.
Let's look at how vasos were prescribed over time,  ie,  the vasos in intervals 0-15 and 15-30:
```{r echo=FALSE }
# so this is action 0, action 1
twotab=table(apply(msa[,2:3],1,paste0,collapse=" "))
twotab2=paste0(twotab," (",round(twotab/sum(twotab)*100,2),"%)")
names(twotab2) = names(twotab)
twotab2
```

It's interesting that so many people start on vasos trajectory (1,1) in the first 15.  I guess if they have a blood pressure measurement of 60, they're in high suspicion to be on vasos quickly. 

## Dropout
We see that some of the people have no second action, it's NA, ostensibly because they leave.   We check that no patients have no first action, and we write the number we exclude based on dropout below.
```{r }
# 
# I checked for people wihtout initial actions.  
# I think these people might have occured before, 
# but I removed them (I think it's just people who were not in the ICU long enough)
no.first = is.na(msa[,1])
print("% without first (why would these occur)")
sum(no.first)/length(no.first)*100

# exclude the cases with missing states
# sometimes there are missing actions, which correspond to missing states
# why is this the case? check Joe's code again.
# but if we remove these it's ok

misa = rep(0,length(msa[,1]))

# note end.stage is like 3, so we exclude only those that don't have actions then.
# careful not to set to eg 5, then we exclude people who drop out in future
for (i in start.t:(end.stage)){
  misa = misa + is.na(msa[,i])
}
#ms=1
#if(ms){
is.misa=misa>0
print(paste("excluding n =",sum(is.misa)))
print("subsetting by first map zero")
take = !is.misa #& first.map.zero

ixs = 1:dim(msa)[1]
newixs = ixs[take]

# check all dimesnions same
#for (i in 1:length(ldf)){
#  print(dim(ldf[[i]]))
#}
```
It is a small number who dropout in the first 30 minutes.  Possibly if they have already survived long enough to have a hypotensive episode, they are robust.

## Initial state covariates, $S_0$ (confounders, on which we will base our decision of how to draw $A_0$)
Recall that $A_0|s_0\sim Bern(expit(\beta^Ts_0)).$
We will show the 9 covariates in $s_0$, which we chose because they were the covariates in Futoma 2020, and Futoma 2020 mentioned that they had consult from a critical care doctor and had Leo Celi, MD, in the acknowledgements. 

Here is a diagram from (https://www.cvphysiology.com/Blood%20Pressure/BP030), which is not an official source, but I think it is a good overview.

![Hypotension etiology.](imagesForPrelimAnalysis/bp030-hypotension-causes.png)

Here are the covariates and descriptions.
```{r, echo=FALSE }
# We consider the 9 covariates from Joe
cov.of.int = c("map","hr","urine","lactate","GCS","creatinine","fio2",
               "bilirubin_total","platelets")#,"total_all_prev_fluids")#,"total_all_prev_vasos")#[1:ncov]
renamed.cov.of.int  =  c("MAP","HR","urine","lactate","GCS","creatinine","Fio2",
                 "bilirubin","platelets")#,"past fluids")#,"past vasos")[1:ncov]
descr = c("Mean Arterial Pressure (1/3 systolic+ 2/3 systolic)","Heart rate (beats per minute)","Urine output (unit?)",
          "Lactate (increases if hypotensive)","Glasgow Coma Score (3 worst, 15 best)","Creatinine (increases if kidney damage)","Fraction inspired oxygen (decreases if hypo?)","Bilirubin (liver)","platetets (clotting)")
cbind(renamed.cov.of.int,descr)
```


## Adjusting for past vasopressors

Note that past vasos are not included in this list.  One could argue that  there is an arrow from past to future vasopressors. 

![On past vasopressors](imagesForPrelimAnalysis/prevvasoadjust.png)


{\color{blue}Note that if we define the action taken before $A_0$ to be $A_{-1},$ then we do not adjust for $A_{-1}$ in the behavioral policy as a confounder, because, by the standard MDP assumptions, the transition probability $S_1|A_0,S_0$ depends only on $A_0,S_0.$ In other words, the standard MDP assumptions consider $S_0$ a sufficient summary of $A_{-1}.$} We think this assumption is reasonable because the duration of action of norepineprhine is so short, which we discuss in the manuscript.


## Proportion vaso vs average reward

Marginal summary of proportion patients given vasos vs average reward (this not so relevant for single stage).  Recall that we define reward $R(S_0,A_0,S_1)=S_1,$ so it's the blood pressure at the next step.

```{r, echo=FALSE }
#png("act.rew.over.time.png",width=1000,height=1000,res=150)
avact = apply(msa,2,mean,na.rm=TRUE) 
avre = apply(msr,2,mean,na.rm=TRUE)
par(mfrow=c(2,1))
plot(c(mst[1,]*60),avact,xlab="time (min)",ylab="prop. given vasos")
plot(c(mst[1,]*60),avre,xlab="time (min)",ylab="avg reward")
#dev.off()
```
We see that reward increases with increasing vasos.

## State covariates
Look at some $S_0$ data
```{r,echo=FALSE }
# S_0
head(ldf[[2]][,cov.of.int])
```

### Univariate

Summary table 
```{r, echo=FALSE }
source('/Volumes/projects/Echo/T32/Birthweightdir/functionsFromT32Dir.R')
# using Sally's summarize function
#summarize(ldf[[3]][,cov.of.int],nmis=TRUE,screen=FALSE)
```

These data look relatively good because Joe preprocessed them. His rules are very complex and tailored to each variable, likely done in consult with critical care experts.

Histograms

We can look at some of the raw, unscaled data.

```{r, echo=FALSE}
#png("RawCovHist.png",width=1000,height=1000,res=150)
par(mfrow=c(3,3))
for (i in 1:length(cov.of.int)){
  hist(ldf[[2]][,cov.of.int[i]],main=paste(cov.of.int[i]))
}
```

Things are often skewed.

### Bivariate

Scatter

We can plot some scatter plots as well, just doing proximal pairs as in the T32 preliminary analysis, and then including the correlation
```{r}
comb=get.sparse.combn(cov.of.int)
par(mfrow=c(3,3))
data.of.int = ldf[[3]]
for (x in comb){
  # thanks to anonymized
  correlation <- round(cor(data.of.int[,x[1]],data.of.int[,x[2]],use="pairwise.complete.obs"),3)
  nobs = sum(!is.na(data.of.int[,x[1]]) & !is.na(data.of.int[,x[2]]))
  plot(data.of.int[,x[1]],data.of.int[,x[2]],xlab = x[1],ylab=x[2],
       cex.lab=1.5)
  #abline(a=0,b=1, lty=2)
  title(paste("r = ",correlation," (n=",nobs,")",sep=""),cex.main=1.2)
}
```
Joe deals with outliers in his scripts (I did not change any of those parts), so we see that the data spread is pretty good.  There are substantial data quality issues with EHR data.  However ICU data, and in particular the lab values, are usually the best data.

We can show correlations.  The heatmap is easier to see maybe, but I include numbers also

Correlation 

```{r }
heatmap(cor(ldf[[3]][,cov.of.int]))
kable(round(cor(ldf[[3]][,cov.of.int]),2))
```

## Average reward vs vaso
We can look at a boxplot of the average reward given vaso or not.  
```{r,echo=FALSE }
# just take decisions between start.t and end.stage
# starting at time start.t
print("subsetting by first map zero")
msr = msr[,start.t:(end.stage),drop=FALSE]
msa = msa[,start.t:(end.stage),drop=FALSE]
ldf = ldf[start.t:(end.stage)]
mst = mst[,start.t:(end.stage),drop=FALSE]


msr=msr[take,,drop=FALSE]
msa = msa[take,,drop=FALSE]
mst = mst[take,,drop=FALSE]
ldf=lapply(ldf,function(x){x[take,,drop=FALSE]})

#png("stagesActRew.png",width=1000,height=dim(msr)[2]*1000,res=150)
par(mfrow=c(dim(msr)[2],1))
for (i in 1:dim(msr)[2]){
  boxplot(msr[,i]~msa[,i],main=paste("stage",i),xlab="Action",ylab="Reward")
}
#dev.off()
```

# Revisiting Patient 201098 in the episode data structure for a single stage decision


Here is just the single stage data not in the episode data structure, but after all data_clean.py, etc

```{r, echo=FALSE}
id.check = which(newixs==id.check)

r=msr[id.check,]
a=msa[id.check,]
#msva[id.check,]
t=round(mst[id.check,],2) # note that these times correspond to the rewards and actions, not states
s=ldf[[1]][id.check,]['map']
kable(c("reward (s_1)"=r,"action (a_0)"=a,time=t,"state (s_0)"=s))
```


Here is the data in the episode data structure  

Behind the scenes here, we create a multistage data object taht can be read directly by the optimization routines, etc.  We will show the single stage data in this format.  Note that MAP is the first covariate.
```{r ,echo=FALSE}

#

# Excluding categorical variables for now
#I also noticed that Joe’s paper only uses 9 variables, so maybe we could follow him. 
#He uses MAP, heart rate, urine output, lactate, Glasgow coma score, 
# serum creatinine, FiO2, total bilirubin, and platelets count. 


#s=s[,c('age','map')]

# it seems like it's too subtle. not enough rewards.
#hist(log(1-r))
#hist(r)




ldf2=lapply(ldf,function(x){x[,cov.of.int,drop=FALSE]})



for (i in 1:length(ldf2)){
  colnames(ldf2[[i]])= cov.of.int
  
}

mseps = get.eps.ms(ldf2[[1]],msa,msr)
print(mseps[[id.check]])
```

# Behavioral policy  (overlap, positivity)

Technically, we are "modeling" when we do the behavioral policy fitting, but it is sort of a preliminary step to the modeling we do later, so I include it here. 

Recall that our estimator for $V_n$ is
\begin{align}
\label{eq:vnest}
V_n(\beta,b_n)= \frac{1}{n}\sum_{i=1}^n \frac{\pi_{\beta}(A_{i,0}=a_{i,0}|S_{i,0}=s_{i,0})}{\pi_{b_n}(A_{i,0}=a_{i,0}|S_{i,0}=s_{i,0})} R(S_{i,0},A_{i,0},S_{i,1}).
\end{align}

We therefore need to estimate $\pi_{b_n}(A_0=1|S_0=s_0),$ which we do with logistic regression.  It is important that $\pi_{b_n}(A_{i,0}=a_{i,0}|S_{i,0}=s_{i,0})$ not equal zero for any $i$, since it is in the denominator, so we check this.

Note that often when we estimate for example the ``effect'' of treatment $A_0$, we are considering the relationship between the action $A_0$ and the outcome, blood pressure, adjusting for confounders in $S_0.$
, and a linear model might be 
\begin{equation}
\label{eq:linearModelExample}
 (S_{i,1})_2 = \tau A_{i,0} + \beta S_{i,0} + \epsilon_i,
 \end{equation}
  where $\tau$ is a treatment effect and $\beta$ is the confounder main effect. 
 Here, as in the literature on statistical decision analysis, we will instead be interested in obtaining a policy $\pi(A_0|S_0),$ which will tell us how to draw a treatment given the initial state. This is the problem the provider and patient must solve at the point of care.
 The linear model in Equation (\ref{eq:linearModelExample}) will actually be considered a part of the "environment," which is encoded in the transition probability. In the case of $R(S_0,A_0,S_{1})=(S_1)_{2}$, it turns out that what we traditionally consider to be the "outcome" and the reward are the same, but this need not be the case; the reward can be any function of $S_0,A_0,$ and $S_1.$
 
 Note that the inverse probability (IPTW) estimator for the effect is
 \[IPTW=E(R(1))-E(R(0))\approx \frac{1}{n}\sum_{i=1}^n \frac{R_i A_i}{\pi_{b_n}(A_i|S_i)}-\frac{1}{n}\sum_{i=1}^n \frac{R_i (1-A_i)}{\pi_{b_n}(A_i|S_i)}\]
 
## Treatment effect, overlap, summary statistics 
```{r }
#eps = get.eps(s,a,r)

#check.pos(eps,cov.of.int)
eps.summ=check.pos(mseps,cov.of.int)
kable(eps.summ$dftb,format="latex",escape=F)
```

In summary, we have a sample size of 4708, a single stage decision (T=1), an action proportion of 0.15 - not bad exploration, adequate overlap, a minimum $\pi_b(a_{i,0}|s_{i,0})$ that is above 0 (note that this is taken over all $a_{i,0}$ and $s_{i,0}$) a strong positive treatment effect (vasos increase blood pressure) both with a IPTW (nonparametric) and parametric outcome model.  

## Behavioral policy coefficients
We conclude with the coefficients of the behavioral policy.  I was not sure how to best check linearity for a GLM, and I am afraid to do so, because I think it is unlikely it holds (although it may hold well enough).

```{r }
ms=summary(eps.summ$beh)
kable(ms$coefficients)
```

## Scaled covariates
We will also plot histograms of the scaled covariates, just to show that scaled covariates are large, so the coefficients are small in teh behavioral policy, but this is because the covariates are large
```{r, echo=FALSE }
##
#browser()
#mseps = sample(mseps)
if (debug){
  eps.mimic = mseps[1:300]
}else{
  eps.mimic=mseps #mseps#[1:1000]#halfds
}


sc=center.scale.s(eps.mimic)
smm=sc$sm.cs


par(mfrow=c(3,3))
for (i in 1:length(cov.of.int)){
  hist(smm[,i],main=paste(cov.of.int[i]))
}


print("SET Sigmas to 1")

ngam*ndel*nlam
scale.s = 1 # for real data, must scale
# for mimic, b0 doesn't matter. only for coverage results

model = 0
if (model){
ixs=select.and.est(eps.mimic,b0=rep(1,dim(eps.mimic[[1]]$Ss[[1]])[1]),
                   gammas=gammas,lambdas=lambdas,
                   deltas=deltas,names=colnames(s),
                   resfile=paste0(exp.tag,"res"),
                   plotfile=paste0(exp.tag,"grid.mimic.png"),
                   scale.s=scale.s,
                   lambda.select.ix=manu.lam.select,gamma.select.ix=gamma.select.ix,
                   use.diff=use.diff,other.args=other.args)
}




```
